{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1.1 — Tokenization: Teaching Machines to Read\n",
    "\n",
    "Companion article: https://medium.com/@vadidsadikshaikh/chapter-1-1-tokenization-teaching-machines-to-read-a82b5f260a3e \n",
    "Reference: Sebastian Raschka, *Build a Large Language Model (From Scratch)*  \n",
    "Purpose: Implement the tokenizer that converts raw text → token IDs using OpenAI’s `tiktoken` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Initialize GPT-2 tokenizer (same as used in GPT-2/3 models)\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "print('✅ Tokenizer loaded successfully')\n",
    "print('Vocabulary size:', tokenizer.n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Large language models read the world as numbers.'\n",
    "encoded = tokenizer.encode(text)\n",
    "\n",
    "print('Original Text:', text)\n",
    "print('Encoded Token IDs:', encoded)\n",
    "print('Number of tokens:', len(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = tokenizer.decode(encoded)\n",
    "print('Decoded Text:', decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Token ID':>10} | {'Token String':<10}\")\n",
    "print('-' * 25)\n",
    "for token_id in encoded:\n",
    "    token_str = tokenizer.decode([token_id])\n",
    "    print(f\"{token_id:>10} | {repr(token_str):<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- This tokenizer uses GPT-2’s Byte Pair Encoding (BPE) algorithm via `tiktoken`.\n",
    "- The output token IDs are the **numerical form** that your model will understand.\n",
    "- These token IDs will be used in the **Embeddings** step (next chapter).\n",
    "- Keep this tokenizer constant throughout your model’s lifecycle (training to deployment)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
